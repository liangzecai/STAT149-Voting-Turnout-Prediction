---
title: "STAT149_project_CV"
author: "Zecai Liang"
date: "4/24/2017"
output: pdf_document
---

```{r}
#### Function to Calculate Discrepency Score ####
# Input: 
        # y.true: factor vector of 'Y' and 'N'
        # y.predict: numeric vector of probabilities

# Output: disprepancy score

model_score = function(y.true, y.predict){
    
    ## convert y.true to binary of 0/1
    y.true = as.numeric(y.true) - 1
    
    ## score
    score = -mean(y.true * log(y.predict + 10^(-23)) + 
                      (1 - y.true) * log(1 - y.predict + 10^(-23)))
    
    return(score)
}
```

For cross validation, we want to report the score on training and test data for each model:

```{r}
#### Function to Calculate Cross-Validation Score (GLM model) ####
# Input: 
        # formular: the formula of glm model
        # data
        # n_fold: k-fold cross validation, default = 10
# Output: the averaged training score and cv score

cv_score_glm = function(formula, data, n_fold = 10, seed = 0){
    set.seed(seed)
    folds_i = sample(1:n_fold, nrow(data), replace = TRUE)
    # vector to store cross validation score
    train_score = 0
    test_score = 0
    
    for (i in 1:n_fold){
        # split data
        train= data[folds_i != i, ]
        test = data[folds_i == i, ]

        # train model
        model = glm(formula, data = train, family = "binomial")
        # predict
        train.predict = predict(model, newdata = train, type = "prob")
        test.predict = predict(model, newdata = test, type = "prob")
        # evaluate score
        score1 = model_score(test$voted, test.predict[,2])
        score2 = model_score(train$voted, train.predict[,2])
        
        train_score = train_score + score1
        test_score = test_score + score2
    }
    
    train_score = train_score / n_fold
    test_score = test_score / n_fold
    
    return(c(train_score, test_score)) 
}

    
```


```{r}
#### Function to Calculate Cross-Validation Score (GAM model) ####
# Input: 
        # formular: the formula of gam model (including s and)
        # data
        # n_fold: k-fold cross validation, default = 10
# Output: the averaged training score and cv score

cv_score_gam = function(formula, data, n_fold = 10, seed = 0){
    set.seed(seed)
    folds_i = sample(1:n_fold, nrow(data), replace = TRUE)
    # vector to store cross validation score
    train_score = 0
    test_score = 0
    
    for (i in 1:n_fold){
        # split data
        train= data[folds_i != i, ]
        test = data[folds_i == i, ]

        # train model
        model = gam(factor(voted) ~., data = train, family = "binomial")
        # predict
        train.predict = predict(model, newdata = train, type = "prob")
        test.predict = predict(model, newdata = test, type = "prob")
        # evaluate score
        score1 = model_score(test$voted, test.predict[,2])
        score2 = model_score(train$voted, train.predict[,2])
        
        train_score = train_score + score1
        test_score = test_score + score2
    }
    
    train_score = train_score / n_fold
    test_score = test_score / n_fold
    
    return(c(train_score, test_score))
}

```


```{r}
#### Function to Calculate Cross-Validation Score (RF model) ####
# Input: 
        # ntree: parameter 'ntree' for randomForest
        # mtry: parameter 'mtry' for randomForest
        # data
        # n_fold: k-fold cross validation, default = 10
# Output: the averaged training score and cv score

cv_score_rf = function(ntree, mtry, data, n_fold = 10, seed = 0){
    set.seed(seed)
    folds_i = sample(1:n_fold, nrow(data), replace = TRUE)
    # vector to store cross validation score
    train_score = 0
    test_score = 0
    
    for (i in 1:n_fold){
        # split data
        train= data[folds_i != i]
        test = data[folds_i == i]

        # train model
        rf = randomForest(factor(voted) ~., data = train, ntree = ntree, mtry = mtry)
       # predict
        train.predict = predict(model, newdata = train, type = "prob")
        test.predict = predict(model, newdata = test, type = "prob")
        # evaluate score
        score1 = model_score(test$voted, test.predict[,2])
        score2 = model_score(train$voted, train.predict[,2])
        
        train_score = train_score + score1
        test_score = test_score + score2
    }
    
    train_score = train_score / n_fold
    test_score = test_score / n_fold
    
    return(c(train_score, test_score))
}
```


