
## 10-fold Cross Validation 1:
ntree = c(100, 200, 300)
mtry = c(2, 4, 6, 8, 10, 12, 14, 16)

## 10-fold Cross Validation 2:
ntree_val = c(400, 500, 600)
mtry_val = c(2, 3, 4, 5, 6, 7)

## 10-fold Cross Validation 3:
ntree = 600
mtry = 2
nodesize = c(1:9)

# Model Submissions:
1: ntree = 600, mtry = 3, loss = 0.55594 (Kaggle)
2: ntree = 600, mtry = 2, loss = 0.55490 (Kaggle)
3: ntree = 600, mtry = 2, nodesize = 9, loss = 0.55437 (Kaggle)

## Feature Importance (on Submission Model 3)
- Permutation Importance or Mean Decrease in Accuracy (MDA): 
assessed for each feature by removing the association between that feature and the target. 
This is achieved by randomly permuting the values of 
the feature and measuring the resulting increase in error. The influence of the correlated features is also removed.
- Gini Importance or Mean Decrease in Impurity (MDI): calculates each feature importance as the 
sum over the number of splits (accross all tress) that include the feature, proportionaly to the number of samples it splits.
ref: https://stats.stackexchange.com/questions/197827/how-to-interpret-mean-decrease-in-accuracy-and-mean-decrease-gini-in-random-fore
